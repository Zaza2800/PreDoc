{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7616fd02",
   "metadata": {},
   "source": [
    "## Tutorial 1: Introduction to PyTorch\n",
    "lien = https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff56773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib_inline.backend_inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from matplotlib.colors import to_rgba\n",
    "from torch import Tensor\n",
    "from tqdm.notebook import tqdm  # Progress bar\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fe1598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.1.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# vérifier sa version\n",
    "print(\"Using torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb817ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24e11252c70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#permettre au code d'être reporductible \n",
    "torch.manual_seed(42)  # Setting the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb0f46",
   "metadata": {},
   "source": [
    "## Créer un tenseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc9de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# Solution 1 : \n",
    "X = Tensor(2, 3, 4)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77443a8f",
   "metadata": {},
   "source": [
    "La fonction torch.Tensor allocates la mémoire pour le tenseur souhaité, mais réutilise toutes les valeurs qui ont déjà été dans la mémoire. Pour affecter directement des valeurs au tenseur lors de l'initialisation, il existe de nombreuses alternatives, dont:\n",
    "\n",
    "\n",
    "\n",
    "torch.zeros: Crée un tenseur rempli de zéros\n",
    "\n",
    "torch.ones: Crée un tenseur rempli de ceux-là\n",
    "\n",
    "torch.rand: Crée un tenseur avec des valeurs aléatoires échantillonnées uniformément entre 0 et 1\n",
    "\n",
    "torch.randn: Crée un tenseur avec des valeurs aléatoires échantillonnées à partir d'une distribution normale avec la moyenne 0 et la variance 1\n",
    "\n",
    "torch.arange: Crée un tenseur contenant les valeurs N,N+1,N+2,...,M\n",
    "\n",
    "torch.Tensor(liste d'intrants): Crée un tenseur à partir des éléments de liste que vous fournissez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425e19d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from a (nested) list\n",
    "x = Tensor([[1, 2], [3, 4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f700822",
   "metadata": {},
   "source": [
    "## Tenseur à Numpy, et Numpy à Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9dd8c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array: [[1 2]\n",
      " [3 4]]\n",
      "PyTorch tensor: tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# numpy -> tenseur \n",
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67089780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch tensor: tensor([0, 1, 2, 3])\n",
      "Numpy array: [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# tenseur -> numpy\n",
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d6b08",
   "metadata": {},
   "source": [
    "## Opération\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db365e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 tensor([[0.9408, 0.1332, 0.9346],\n",
      "        [0.5936, 0.8694, 0.5677]])\n",
      "X2 tensor([[0.7411, 0.4294, 0.8854],\n",
      "        [0.5739, 0.2666, 0.6274]])\n"
     ]
    }
   ],
   "source": [
    "#Aléatoire \n",
    "\n",
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "\n",
    "print(\"X1\", x1)\n",
    "print(\"X2\", x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfef2298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 (before) tensor([[0.7890, 0.2814, 0.7886],\n",
      "        [0.5895, 0.7539, 0.1952]])\n",
      "X2 (before) tensor([[0.0050, 0.3068, 0.1165],\n",
      "        [0.9103, 0.6440, 0.7071]])\n",
      "X1 (after) tensor([[0.7890, 0.2814, 0.7886],\n",
      "        [0.5895, 0.7539, 0.1952]])\n",
      "X2 (after) tensor([[0.7941, 0.5882, 0.9051],\n",
      "        [1.4997, 1.3979, 0.9024]])\n"
     ]
    }
   ],
   "source": [
    "#Additionner terme par terme \n",
    "\n",
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "print(\"X1 (before)\", x1)\n",
    "print(\"X2 (before)\", x2)\n",
    "\n",
    "x2.add_(x1)\n",
    "print(\"X1 (after)\", x1)\n",
    "print(\"X2 (after)\", x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab1e8d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 (before) tensor([[0.7860, 0.1115, 0.2477],\n",
      "        [0.6524, 0.6057, 0.3725]])\n",
      "X1 (after) tensor([[0.7860],\n",
      "        [0.1115],\n",
      "        [0.2477],\n",
      "        [0.6524],\n",
      "        [0.6057],\n",
      "        [0.3725]])\n"
     ]
    }
   ],
   "source": [
    "# Rearranger \n",
    "\n",
    "x1 = torch.rand(2, 3)\n",
    "print(\"X1 (before)\", x1)\n",
    "x1 = x1.view(6, 1)\n",
    "print(\"X1 (after)\", x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a19c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0.7860, 0.1115, 0.2477, 0.6524, 0.6057, 0.3725]])\n"
     ]
    }
   ],
   "source": [
    "x1 = x1.permute(1, 0)  # Swapping dimension 0 and 1\n",
    "print(\"X\", x1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea324d8a",
   "metadata": {},
   "source": [
    "D'autres opérations couramment utilisées incluent les multiplications matricielles, qui sont essentielles pour les réseaux neuronaux. Très souvent, nous avons un vecteur d'entrée\\mathbf{x}, qui est transformé à l'aide d'une matrice de poids apprise\\mathbf{W}. Il y a plusieurs façons et fonctions pour effectuer la multiplication matricielle, dont on énumère quelques-unes ci-dessous:\n",
    "\n",
    "    torch.matmul: Effectue le produit de la matrice sur deux tenseurs, où le comportement spécifique dépend des dimensions. Si les deux entrées sont des matrices (protenseurs de 2 dimensions), elles réalisent le produit de matrice standard. Pour les entrées de dimension supérieure, la fonction prend en charge la diffusion (pour plus de détails, voir la documentation). Peut également être écrit sous la forme d'un a @ b, à l'instar de numpy.\n",
    "\n",
    "    torch.mm: Effectue le produit matriciel sur deux matrices, mais ne supporte pas la diffusion (voir documentation)\n",
    "\n",
    "    torch.bmm: Effectue le produit de la matrice avec une dimension de lot de support. Si le premier tenseur Test de forme (b\\times n\\times m), et le deuxième tenseur R(b\\times m\\times p), la sortie Oest de forme (b\\times n\\times p), et a été calculée en effectuant bdes multiplications matricielles des sous-matrices de TRet: O_i = T_i @ R_i\n",
    "\n",
    "    torch.einsum: Effectue des multiplications de matrices et plus (c'est-à-dire des sommes de produits) en utilisant la convention de sommation d'Einstein. L'explication de la somme d'Einstein peut être trouvée dans l'assignation 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d954a02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "W tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "h tensor([[15, 18, 21],\n",
      "        [42, 54, 66]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)\n",
    "\n",
    "W = torch.arange(9).view(3, 3)  # We can also stack multiple operations in a single line\n",
    "print(\"W\", W)\n",
    "\n",
    "h = torch.matmul(x, W)  # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a847891",
   "metadata": {},
   "source": [
    "## Calcul dynamique et retropropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad8cec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#La première chose que nous devons faire est de préciser quels tenseurs nécessitent des gradients. \n",
    "#Par défaut, lorsque nous créons un tenseur, il ne nécessite pas de gradients.\n",
    "\n",
    "\n",
    "x = torch.ones((3,))\n",
    "print(x.requires_grad)\n",
    "x.requires_grad_(True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09d65a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([0., 1., 2.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32, requires_grad=True)  # Only float tensors can have gradients\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0b37d",
   "metadata": {},
   "source": [
    "y = \\frac{1}{|x|}\\sum_i\\left[(x_i+2)^2+3 \\right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ce5866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = x + 2\n",
    "b = a**2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7127016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()\n",
    "#Désormais c'est x.grad qui contient la dérivé de y par rapport à x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04356f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3333, 2.0000, 2.6667])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36a971",
   "metadata": {},
   "source": [
    "## GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06ac039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? False\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7df4ca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61461e",
   "metadata": {},
   "source": [
    "## Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26f3530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle de base \n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Some init for my module\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Function for performing the calculation of the module.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modele avec une couche une couche dense (linear)\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # Initialize the modules we need to build the network\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
