{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccc5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0b0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamaestro import prepare_dataset\n",
    "ds = prepare_dataset(\"com.lecun.mnist\");\n",
    "train_images, train_labels = ds.train.images.data(), ds.train.labels.data()\n",
    "test_images, test_labels =  ds.test.images.data(), ds.test.labels.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1458c",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "Implémenter un dataset pour le jeu de données MNIST qui renvoie une image\n",
    "sous la forme d’un vecteur normalisé entre 0 et 1, et le label associé (sans utiliser\n",
    "TensorDataset). Tester votre dataset avec un dataloader pour différentes tailles de\n",
    "batch et explorer les options du dataloader.\n",
    "Vous pouvez vous référer à la doc officielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e59309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verfier le nombre d'image dans le train max -> (60000, 28, 28)\n",
    "# idem pour test -> (10000, 28, 28)\n",
    "train_images = train_images/train_images.max()\n",
    "test_images = test_images/test_images.max()\n",
    "batch = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2eaf80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# on s'assure que les images sont normalisés\n",
    "print(train_images.min(),train_images.max(),test_images.min(),test_images.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "349fb8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enza6\\AppData\\Local\\Temp\\ipykernel_26472\\2399840432.py:4: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  train_labels = torch.from_numpy(train_labels)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "#Pour utiliser Tensor il faut que ca soit des tensors... \n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "train_images = torch.from_numpy(train_images)\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "\n",
    "test_labels = torch.from_numpy(test_labels)\n",
    "test_images = torch.from_numpy(test_images)\n",
    "test_dataset = TensorDataset(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cdcac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(dataset=train_dataset, batch_size = batch, shuffle = True)\n",
    "test_data = DataLoader(dataset=test_dataset, batch_size = batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792cc7a",
   "metadata": {},
   "source": [
    "## Gestion mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a48455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else ('cpu'))\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e228d6",
   "metadata": {},
   "source": [
    "## Checkpointing\n",
    "Créer une classe pour stocker l'état du modèle et de l'optimiseur lors de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c8071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State : \n",
    "    def __init__(self, model, optim) -> None:\n",
    "        self.model = model \n",
    "        self.optim = optim\n",
    "        self.epoch, self.iteration = 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966f3b1",
   "metadata": {},
   "source": [
    "Dans les itérations d'entraînement : \n",
    "    Réinitialise les gradients de l'optimiseur avec state.optim.zero_grad().\n",
    "    Déplace les données d'entrée x vers le périphérique spécifié (device).\n",
    "    Passe les données d'entrée x dans le modèle state.model pour obtenir les prédictions xhat.\n",
    "    Calcule la perte (loss) entre les prédictions xhat et les données d'entrée x.\n",
    "    Effectue la rétropropagation (backpropagation) de la perte pour calculer les gradients.\n",
    "    Applique une étape d'optimisation avec state.optim.step() pour mettre à jour les poids du modèle.\n",
    "    Incrémente le compteur d'itérations state.iteration\n",
    "\n",
    "A la fin de chaque époque, il sauvegarde l'état courant de l'entrainement dans un fichier créer au debut en utilisant 'torch.save'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be8c10",
   "metadata": {},
   "source": [
    "## Implémentation d'un autoencodeur\n",
    "Implémenter une classe autoencodeur (héritée de Module) selon l’architecture sui-\n",
    "vante : linéaire → Relu pour la partie encodage et linéaire → sigmoïde pour la partie\n",
    "décodage. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349528ae",
   "metadata": {},
   "source": [
    "Les poids du décodeur correspondent usuellement à la transposée des poids\n",
    "de l’encodeur (quel est l’avantage ?)\n",
    "\n",
    "[A répondre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff4a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module): \n",
    "    def __init__(self):\n",
    "        #beginning size image = 784\n",
    "        super(Autoencoder, self).__init__() \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(test_images.shape[1]*test_images.shape[2],128), # 784->128\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64,12),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(12,3)# N -> 3 \n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3,12),\n",
    "            nn.Sigmoid(), \n",
    "            nn.Linear(12,64),\n",
    "            nn.Sigmoid(), \n",
    "            nn.Linear(64,128),\n",
    "            nn.Sigmoid(), \n",
    "            nn.Linear(128,test_images.shape[1]*test_images.shape[2]),\n",
    "            ## need a active fonction wich but value between 0 and 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        pass\n",
    "    \n",
    "    def forward (self, x): \n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73dd2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ac49ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"log\"\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aec009b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/10,Loss:0.20252125054597855\n",
      "Epoch:2/10,Loss:0.14667908685902756\n",
      "Epoch:3/10,Loss:0.10919386795411508\n",
      "Epoch:4/10,Loss:0.08875401835888624\n",
      "Epoch:5/10,Loss:0.07861191418021918\n",
      "Epoch:6/10,Loss:0.07362142692009609\n",
      "Epoch:7/10,Loss:0.07103535457203786\n",
      "Epoch:8/10,Loss:0.06960473871479432\n",
      "Epoch:9/10,Loss:0.0687680820375681\n",
      "Epoch:10/10,Loss:0.06825562366594871\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "num_epochs = 10\n",
    "outputs    = []\n",
    "for epoch in range(num_epochs): \n",
    "    LOSS = []\n",
    "    for (img, _) in train_data: \n",
    "        #on prend les images une par une\n",
    "        img   = img.reshape(-1, train_images.shape[1]*train_images.shape[2])\n",
    "        #reconstructed image \n",
    "        img = img.float()\n",
    "        recon = model(img)\n",
    "        loss  = criterion(recon, img)\n",
    "        \n",
    "        writter.add_scalar(\"Loss\",loss, epoch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        LOSS.append(loss.item())\n",
    "        outputs.append((epoch,img,recon))\n",
    "    print(f'Epoch:{epoch+1}/{num_epochs},Loss:{sum(LOSS)/len(LOSS)}')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59a40d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss : 0.0007\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "model.eval()\n",
    "outputs    = []\n",
    "test_loss = 0.0\n",
    "for (img, _) in test_data: \n",
    "    #on prend les images une par une\n",
    "    img   = img.reshape(-1, train_images.shape[1]*train_images.shape[2])\n",
    "    #reconstructed image \n",
    "    img = img.float()\n",
    "    recon = model(img)\n",
    "    loss  = criterion(recon, img)\n",
    "       \n",
    "    writter.add_scalar(\"Loss\",loss)\n",
    "        \n",
    "    test_loss += loss.item()\n",
    "            \n",
    "average_loss = test_loss/len(test_labels)\n",
    "print(f'Average Test Loss : {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05a91593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-480a3ae52b06850f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-480a3ae52b06850f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45bb20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
