{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d40a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enza6\\anaconda3\\envs\\AMAL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\enza6\\anaconda3\\envs\\AMAL\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "## Installer datamaestro et datamaestro-ml pip install datamaestro datamaestro-ml\n",
    "import datamaestro\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a950d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41d61f",
   "metadata": {},
   "source": [
    "# Téléchargement du dataset du cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b950d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datamaestro.prepare_dataset(\"edu.uci.boston\")\n",
    "colnames, datax, datay = data.data()\n",
    "datax = torch.tensor(datax,dtype=torch.float)\n",
    "datay = torch.tensor(datay,dtype=torch.float).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "758bd3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 13])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b5aed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259ccda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datay.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b3a88",
   "metadata": {},
   "source": [
    "# Téléchargement du dataset random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8b31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = torch.rand(datax.shape[0], datax.shape[1])\n",
    "datay = torch.rand(datay.shape[0], datay.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e2136",
   "metadata": {},
   "source": [
    "# Séparer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5814765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(datax, datay, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8824b3",
   "metadata": {},
   "source": [
    "# Modèle régréssion classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e9ab83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(X, W, b) : \n",
    "    return X@W.t()+b\n",
    "\n",
    "def MSE(ytrue, y)   : \n",
    "    return ((ytrue - y)**2).mean()\n",
    "\n",
    "def linear_regression(dataX, dataY): \n",
    "    W = torch.rand((dataY.shape[1], dataX.shape[1]),requires_grad=True)\n",
    "    b = torch.rand((1, dataY.shape[1]),requires_grad=True)\n",
    "    \n",
    "    Epochs = 20\n",
    "    eps    = 1e-2\n",
    "    \n",
    "    \n",
    "    loss_list = []\n",
    "    for e in range(Epochs) : \n",
    "        Y = linear(dataX, W, b)\n",
    "        mse = MSE(dataY, Y) \n",
    "        print(mse)\n",
    "        mse.backward()\n",
    "        loss_list.append(mse)\n",
    "        with torch.no_grad(): \n",
    "            W -= eps* W.grad \n",
    "            b -= eps* b.grad\n",
    "        # Peut aussi faire w.data -= eps * w.grad\n",
    "        \n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_() \n",
    "        #tf.summary.scalar('Loss', loss_list, step=e)\n",
    "    return loss_list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c7cc34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training ---\n",
      "tensor(15.8484, grad_fn=<MeanBackward0>)\n",
      "tensor(13.3313, grad_fn=<MeanBackward0>)\n",
      "tensor(11.2191, grad_fn=<MeanBackward0>)\n",
      "tensor(9.4466, grad_fn=<MeanBackward0>)\n",
      "tensor(7.9591, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7108, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6632, grad_fn=<MeanBackward0>)\n",
      "tensor(4.7841, grad_fn=<MeanBackward0>)\n",
      "tensor(4.0463, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4272, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9075, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4714, grad_fn=<MeanBackward0>)\n",
      "tensor(2.1054, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7982, grad_fn=<MeanBackward0>)\n",
      "tensor(1.5404, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3239, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1422, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8617, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7542, grad_fn=<MeanBackward0>)\n",
      "--- Test ---\n",
      "tensor(16.4543, grad_fn=<MeanBackward0>)\n",
      "tensor(13.7006, grad_fn=<MeanBackward0>)\n",
      "tensor(11.4125, grad_fn=<MeanBackward0>)\n",
      "tensor(9.5113, grad_fn=<MeanBackward0>)\n",
      "tensor(7.9315, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6189, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5281, grad_fn=<MeanBackward0>)\n",
      "tensor(4.6218, grad_fn=<MeanBackward0>)\n",
      "tensor(3.8686, grad_fn=<MeanBackward0>)\n",
      "tensor(3.2428, grad_fn=<MeanBackward0>)\n",
      "tensor(2.7228, grad_fn=<MeanBackward0>)\n",
      "tensor(2.2906, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9315, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6330, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3850, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1788, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0075, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8651, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7467, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6483, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('--- Training ---')\n",
    "train_loss = linear_regression(X_train, Y_train)\n",
    "train_loss = [train_item.detach().numpy() for train_item in train_loss]\n",
    "print('--- Test ---')\n",
    "test_loss = linear_regression(X_test, Y_test)\n",
    "test_loss = [test_item.detach().numpy() for test_item in test_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c0a74b",
   "metadata": {},
   "source": [
    "# Utiliser tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca4ac6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_tensorboard(dataX, dataY): \n",
    "    W = torch.rand((dataY.shape[1], dataX.shape[1]),requires_grad=True)\n",
    "    b = torch.rand((1, dataY.shape[1]),requires_grad=True)\n",
    "    #enregistre les journaux Tensorboard (données loss)\n",
    "    writer = SummaryWriter('log')\n",
    "    Epochs = 20\n",
    "    eps    = 1e-2\n",
    "    \n",
    "    \n",
    "    loss_list = []\n",
    "    for e in range(Epochs) : \n",
    "        Y = linear(dataX, W, b)\n",
    "        mse = MSE(dataY, Y) \n",
    "        print(mse)\n",
    "        mse.backward()\n",
    "        #loss_list.append(mse)\n",
    "        writer.add_scalar('Train Loss', mse, e)\n",
    "        with torch.no_grad(): \n",
    "            W -= eps* W.grad \n",
    "            b -= eps* b.grad\n",
    "        # Peut aussi faire w.data -= eps * w.grad\n",
    "        \n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_() \n",
    "    writer.close()\n",
    "    return writer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96ad127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training ---\n",
      "tensor(6.8678, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8055, grad_fn=<MeanBackward0>)\n",
      "tensor(4.9140, grad_fn=<MeanBackward0>)\n",
      "tensor(4.1658, grad_fn=<MeanBackward0>)\n",
      "tensor(3.5379, grad_fn=<MeanBackward0>)\n",
      "tensor(3.0109, grad_fn=<MeanBackward0>)\n",
      "tensor(2.5685, grad_fn=<MeanBackward0>)\n",
      "tensor(2.1972, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8856, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6240, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4044, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2200, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0652, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9352, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8260, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7343, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6573, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5926, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5382, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4924, grad_fn=<MeanBackward0>)\n",
      "--- Test ---\n",
      "tensor(8.4235, grad_fn=<MeanBackward0>)\n",
      "tensor(7.0216, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8568, grad_fn=<MeanBackward0>)\n",
      "tensor(4.8889, grad_fn=<MeanBackward0>)\n",
      "tensor(4.0846, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4163, grad_fn=<MeanBackward0>)\n",
      "tensor(2.8610, grad_fn=<MeanBackward0>)\n",
      "tensor(2.3996, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0162, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6976, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4328, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2128, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0299, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8780, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7517, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6467, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5595, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4869, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4266, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3765, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('--- Training ---')\n",
    "train_loss = linear_regression_tensorboard(X_train, Y_train)\n",
    "\n",
    "print('--- Test ---')\n",
    "test_loss = linear_regression(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bfcd0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faire les plots des images \n",
    "#https://pytorch.org/docs/stable/tensorboard.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8433c",
   "metadata": {},
   "source": [
    "# Modele opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "80c55b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_opti(dataX, dataY): \n",
    "    W = torch.rand((dataY.shape[1], dataX.shape[1]),requires_grad=True)\n",
    "    b = torch.rand((1, dataY.shape[1]),requires_grad=True)\n",
    "    \n",
    "    Epochs = 10\n",
    "    eps    = 1e-3\n",
    "    optim = torch.optim.SGD([W,b], lr=eps)\n",
    "    \n",
    "    loss_list = []\n",
    "    for e in range(Epochs) : \n",
    "        Y   = linear(dataX, W, b)\n",
    "        mse = MSE(dataY, Y) \n",
    "        print(mse)\n",
    "        mse.backward()\n",
    "        \n",
    "        #a la place de \n",
    "        \n",
    "        loss_list.append(mse)\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "    return loss_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b1b47145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training ---\n",
      "tensor(8.3837, grad_fn=<MeanBackward0>)\n",
      "tensor(7.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8862, grad_fn=<MeanBackward0>)\n",
      "tensor(4.9371, grad_fn=<MeanBackward0>)\n",
      "tensor(4.1445, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4826, grad_fn=<MeanBackward0>)\n",
      "tensor(2.9298, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4681, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0825, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7605, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4916, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2670, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0794, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9227, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7919, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6826, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5913, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5150, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4513, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3980, grad_fn=<MeanBackward0>)\n",
      "--- Test ---\n",
      "tensor(9.6625, grad_fn=<MeanBackward0>)\n",
      "tensor(8.1087, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8082, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7195, grad_fn=<MeanBackward0>)\n",
      "tensor(4.8083, grad_fn=<MeanBackward0>)\n",
      "tensor(4.0455, grad_fn=<MeanBackward0>)\n",
      "tensor(3.4070, grad_fn=<MeanBackward0>)\n",
      "tensor(2.8725, grad_fn=<MeanBackward0>)\n",
      "tensor(2.4250, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0505, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7370, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4745, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2547, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0708, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9167, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7878, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6798, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5894, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5136, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4502, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('--- Training ---')\n",
    "train_loss = linear_regression(X_train, Y_train)\n",
    "train_loss = [train_item.detach().numpy() for train_item in train_loss]\n",
    "print('--- Test ---')\n",
    "test_loss = linear_regression(X_test, Y_test)\n",
    "test_loss = [test_item.detach().numpy() for test_item in test_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2abf2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_module(dataX, dataY):\n",
    "    m_lineaire = torch.nn.Linear(DIM, NB_OUT)\n",
    "    loss = torch.nn.MSELoss()\n",
    "\n",
    "    EPOCHS = 100\n",
    "    eps = 1e-3\n",
    "    optim = torch.optim.SGD(m_lineaire.parameters(), lr=eps)\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "         mse = loss.forward(dataY, m_lineaire.forward(dataX))\n",
    "         # mse = loss(dataY, m_lineaire(dataX))\n",
    "         print(mse)\n",
    "         mse.backward()\n",
    "         optim.step()\n",
    "         optim.zero_grad()\n",
    "\n",
    "\n",
    "NB_OUT_1 = 5\n",
    "NB_OUT_2 = 5\n",
    "\n",
    "def reg_module_2(dataX, dataY):\n",
    "    m1 = torch.nn.Linear(DIM, NB_OUT_1)\n",
    "    m2 = torch.nn.Linear(NB_OUT_1, NB_OUT_2)\n",
    "    loss = torch.nn.MSELoss()\n",
    "\n",
    "    EPOCHS = 100\n",
    "    eps = 1e-3\n",
    "    optim = torch.optim.SGD(list(m1.parameters()) + list(m2.parameters()), lr=eps)\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "         z = m1(dataX)\n",
    "         z = torch.nn.functional.tanh(z)\n",
    "         z = m2(z)\n",
    "         mse = loss(dataY, z)\n",
    "         print(mse)\n",
    "         mse.backward()\n",
    "         optim.step()\n",
    "         optim.zero_grad()\n",
    "\n",
    "\n",
    "def reg_module_seq(dataX, dataY):\n",
    "    m1 = torch.nn.Linear(DIM, NB_OUT_1)\n",
    "    m2 = torch.nn.Linear(NB_OUT_1, NB_OUT_2)\n",
    "    loss = torch.nn.MSELoss()\n",
    "\n",
    "    reseau = torch.nn.Sequential(m1, torch.nn.Tanh, m2)\n",
    "\n",
    "    optim = torch.optim.SGD(reseau.parameters(), lr=eps)\n",
    "\n",
    "    EPOCHS = 100\n",
    "    eps = 1e-3\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "         z = reseau(dataX)\n",
    "         mse = loss(dataY, z)\n",
    "         print(mse)\n",
    "         mse.backward()\n",
    "         optim.step()\n",
    "         optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a8669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez un objet SummaryWriter en spécifiant le répertoire des journaux\n",
    "writer = SummaryWriter(\"runs/train\")\n",
    "\n",
    "# Ajoutez quelques métriques factices à TensorBoard\n",
    "for i in range(10):\n",
    "    writer.add_scalar(\"Loss\", 0.1 * i, i)\n",
    "    writer.add_scalar(\"Accuracy\", 1.0 - 0.1 * i, i)\n",
    "\n",
    "# Ajoutez une image factice à TensorBoard\n",
    "fake_image = torch.randn(3, 64, 64)\n",
    "writer.add_image(\"Fake Image\", fake_image, 0)\n",
    "\n",
    "# Fermez l'objet SummaryWriter\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aac86cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5704), started 0:13:28 ago. (Use '!kill 5704' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3d89feca20e5f709\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3d89feca20e5f709\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4ade51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'--logdir' n’est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exécutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!--logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e036274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
